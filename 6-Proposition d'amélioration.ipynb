{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Proposition d'amélioration\n",
    "\n",
    "Dans cette partie, nous allons proposer des améliorations au conditions de travail des employés pour résoudre le problème de HumanForYou.\n",
    "\n",
    "Nous allons chercher a modifier les conditions de travail dans le sens de nos trouvailles graves aux résultats précédents.\n",
    "\n",
    "Nous avons découvert grâce au calcule de la variation des valeurs du model `MultiLayeredPercepton` que les trois facons de diminuer le temps de travail moyen et augmenter le temps de formation de l'année passée.\n",
    "\n",
    "Nous allons donc modifier ces variables dans leurs sens respectifs pour esperer en tirer un taux d'attretion faible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "md = pd.read_excel(\"./buffer/1-main_dataset.xlsx\")\n",
    "md.drop(columns=md.columns[0], axis=1, inplace=True)\n",
    "\n",
    "X = md.drop(columns=\"Attrition\", axis=1)\n",
    "y = [i == \"Yes\" for i in md[\"Attrition\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,  random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_dict = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 5}, max_depth=30, min_samples_leaf= 3, min_samples_split=2, n_estimators=130),\n",
    "    'Logistic Regression': LogisticRegression(C=0.15, penalty=\"l2\"),\n",
    "    'Multi Layered Perceptron': MLPClassifier(random_state=42, alpha=0.1, hidden_layer_sizes=100, max_iter=1600, solver='lbfgs')\n",
    "}\n",
    "\n",
    "# Get the list of columns depending on there type\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "      ('imputer', SimpleImputer(strategy='median')),\n",
    "      ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "      ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "      ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "      ('num', numeric_transformer, numeric_features),\n",
    "      ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "full_pipeline_dict = {}\n",
    "for name, model in model_dict.items():\n",
    "      full_pipeline_dict[name] = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            (name, model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score: 0.9807256235827665\n",
      "Logistic Regression score: 0.8503401360544217\n",
      "Multi Layered Perceptron score: 0.9909297052154195\n"
     ]
    }
   ],
   "source": [
    "y_pred_dict = {}\n",
    "\n",
    "for name, pipeline in full_pipeline_dict.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    y_pred_dict[name] = pipeline.predict(X_test)\n",
    "    print(f\"{name} score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Attrition: 145\n",
      "Predicted Attrition: {'Random Forest': 128, 'Logistic Regression': 59, 'Multi Layered Perceptron': 143}\n",
      "Improved Attrition: {'Random Forest': 45, 'Logistic Regression': 0, 'Multi Layered Perceptron': 3}\n"
     ]
    }
   ],
   "source": [
    "offset_dict = {\n",
    "    'Average': -0.2,\n",
    "    'TrainingTimesLastYear': 2\n",
    "}\n",
    "\n",
    "X_test_mod = X_test.copy()\n",
    "\n",
    "for key, val in offset_dict.items():\n",
    "    X_test_mod[key] += np.array( [val] * len(X_test_mod[key]))\n",
    "\n",
    "y_pred_mod_dict = {}\n",
    "for name, pipeline in full_pipeline_dict.items():\n",
    "    y_pred_mod_dict[name] = pipeline.predict(X_test_mod)\n",
    "\n",
    "print(f\"Real Attrition: {sum(y_test)}\\nPredicted Attrition: { {k:sum(v) for k, v in y_pred_dict.items()} }\\nImproved Attrition: { {k:sum(v) for k, v in y_pred_mod_dict.items()} }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Graces aux recherches effectuées précédament et au models développés à partir des données des employées, nous avons pue proposer une solution à HumanForYou pour diminuer leur taux d'attertion.\n",
    "\n",
    "Cette solution est étique car elle ne cause aucune discrimination et permet juste de modifier les confditions de travail pour arriver a de meilleurs résultats.\n",
    "\n",
    "Si cette solution ne convient pas a HumanForYou, les models et données éxtraitres permetterons surement aux personnes concerner de trouver un comprmis. De plus, il sera facile pour eux de tester leurs solution avec notre model en modifiant le dictionaire `offset_dict`. Il sera par contre demander de prendre en compte l'étique lors de cette opération."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ee1ad32b56d89343f866cbb24efe029c7376ac3acaed8ce40e8302e13a6cb77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
